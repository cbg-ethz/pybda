Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	clustering_fit
	1	fa
	1	fa_sample
	1	fa_sample_plot
	1	outliers
	6

rule fa:
    input: README.md
    output: data/fa
    jobid: 1

Finished job 1.
1 of 6 steps (17%) done

rule fa_sample:
    input: data/fa
    output: data/fa-sample.tsv
    jobid: 4

Finished job 4.
2 of 6 steps (33%) done

rule outliers:
    input: data/fa
    output: data/outlier-removal
    jobid: 3

Finished job 3.
3 of 6 steps (50%) done

rule clustering_fit:
    input: data/outlier-removal
    output: data/kmeans-2,3,4,5,6
    jobid: 5

Finished job 5.
4 of 6 steps (67%) done

rule fa_sample_plot:
    input: data/fa-sample.tsv
    output: data/fa-sample-distribution.eps
    jobid: 2

Finished job 2.
5 of 6 steps (83%) done

localrule all:
    input: data/fa, data/fa-sample.tsv, data/fa-sample-distribution.eps, data/outlier-removal, data/kmeans-2,3,4,5,6, data/kmeans-plot.eps
    jobid: 0

Finished job 0.
6 of 6 steps (100%) done
Complete log: /Users/simondi/PROJECTS/target_infect_x_project/src/tix-analysis/.snakemake/log/2018-05-11T175904.156368.snakemake.log
