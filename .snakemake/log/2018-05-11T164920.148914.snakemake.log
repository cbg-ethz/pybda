Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	fa
	1	fa_sample
	1	fa_sample_plot
	4

rule fa:
    input: README.md
    output: data/fa
    jobid: 1

Finished job 1.
1 of 4 steps (25%) done

rule fa_sample:
    input: data/fa
    output: data/fa-sample.tsv
    jobid: 4

Finished job 4.
2 of 4 steps (50%) done

rule fa_sample_plot:
    input: data/fa-sample.tsv
    output: data/fa-sample-distribution.eps
    jobid: 3

Finished job 3.
3 of 4 steps (75%) done

localrule all:
    input: data/fa, data/fa-sample.tsv, data/fa-sample-distribution.eps, data/outlier-removal, data/kmeans-2
    jobid: 0

Finished job 0.
4 of 4 steps (100%) done
Complete log: /Users/simondi/PROJECTS/target_infect_x_project/src/tix-analysis/.snakemake/log/2018-05-11T164920.148914.snakemake.log
