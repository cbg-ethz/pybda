Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	clustering_fit
	1	clustering_transform
	1	fa
	1	fa_sample
	1	fa_sample_plot
	1	outliers
	7

rule fa:
    input: data/single_cell_samples.tsv
    output: data/fa.log
    jobid: 3

Finished job 3.
1 of 7 steps (14%) done

rule outliers:
    input: data/fa.log
    output: data/outlier-removal.log
    jobid: 5

Finished job 5.
2 of 7 steps (29%) done

rule clustering_fit:
    input: data/outlier-removal.log
    output: data/kmeans-fit.log
    jobid: 6

Error in rule clustering_fit:
    jobid: 6
    output: data/kmeans-fit.log

RuleException:
NameError in line 50 of /Users/simondi/PROJECTS/target_infect_x_project/src/tix-analysis/biospark.snake:
The name 'spark' is unknown in this context. Please make sure that you defined that variable. Also note that braces not used for variable access have to be escaped by repeating them, i.e. {{print $1}}
  File "/Users/simondi/PROJECTS/target_infect_x_project/src/tix-analysis/biospark.snake", line 50, in __rule_clustering_fit
  File "/Users/simondi/anaconda3/envs/py36/lib/python3.6/concurrent/futures/thread.py", line 56, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /Users/simondi/PROJECTS/target_infect_x_project/src/tix-analysis/.snakemake/log/2018-05-12T233253.057814.snakemake.log
