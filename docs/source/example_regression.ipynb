{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Dimension reduction\n",
    "-------------------\n",
    "\n",
    "Here we show a small use case of how to do a dimension reduction on a small sample data set\n",
    "(``data/iris.tsv``). We assume you\n",
    "already set up the cluster for Spark (other check `here <./usage.html#spark>`__) with\n",
    "an ``IP`` address.\n",
    "\n",
    "Analysis\n",
    "........\n",
    "\n",
    "For analysis we decide use a linear discriminant analysis to map data into a lower dimensional space.\n",
    "PyBDA offers the following methods to do dimension reduction:\n",
    "\n",
    "* ``pca`` for `principal component analysis <https://en.wikipedia.org/wiki/Principal_component_analysis>`__,\n",
    "* ``factor_analysis`` `for factor analysis <https://en.wikipedia.org/wiki/Factor_analysis>`__,\n",
    "* ``kpca`` for `kernel principal component analysis <https://en.wikipedia.org/wiki/Kernel_principal_component_analysis>`_ using Fourier features to approximate the kernel,\n",
    "* ``lda`` for `linear discriminant analysis <https://en.wikipedia.org/wiki/Linear_discriminant_analysis>`__,\n",
    "* ``ica`` for `independent component analysis <https://en.wikipedia.org/wiki/Independent_component_analysis>`__.\n",
    "\n",
    "The config file we need to specify is in this case rather concise:\n",
    "\n",
    ".. literalinclude:: ../../data/pybda-usecase-dimred.config\n",
    "  :caption: Contents of ``data/pybda-usecase-dimred.config`` file\n",
    "  :name: pybda-usecase-dimred.config\n",
    "\n",
    "In the config above we will do the following:\n",
    "\n",
    "* Use a linear discriminant analysis to map the data set into a two-dimensional space using ``Species`` as a response.\n",
    "* give the Spark driver 1G of memory and the executor 1G of memory.\n",
    "\n",
    "Having the parameters set, we call PyBDA\n",
    "\n",
    ".. code-block:: bash\n",
    "\n",
    "  pybda dimension-reduction pybda-usecase-dimred.config IP\n",
    "\n",
    "Clustering\n",
    "----------\n",
    "\n",
    "Here we show a small use case of how to cluster data on a small sample data set\n",
    "(``data/iris.tsv``). We assume you\n",
    "already set up the cluster for Spark (other check `here <./usage.html#spark>`__) with an ``IP`` address.\n",
    "\n",
    "Analysis\n",
    "........\n",
    "\n",
    "For analysis we decide to use a simple k-means with various cluster centers. All\n",
    "methods for clustering are:\n",
    "\n",
    "* ``kmeans`` for `K-means <https://en.wikipedia.org/wiki/K-means_clustering>`__,\n",
    "* ``gmm`` for `Gaussian mixture models <https://en.wikipedia.org/wiki/Mixture_model#Gaussian_mixture_model>`__.\n",
    "\n",
    "In order to account for correlated features, we first map the features into a lower\n",
    "dimensional space using factor analysis (we could also use a GMM, where we estimate\n",
    "the correlations too, or remove the line in the config):\n",
    "\n",
    ".. literalinclude:: ../../data/pybda-usecase-clustering.config\n",
    "  :caption: Contents of ``data/pybda-usecase-clustering.config`` file\n",
    "  :name: pybda-usecase-clustering.config\n",
    "\n",
    "In the config above we will do the following.\n",
    "\n",
    "* Use a factor analysis into a space with two dimensions on the features in ``data/iris_feature_columns.tsv``,\n",
    "* do a clustering with 2, 3 and 5 cluster centers on the two features we got from the factor analysis,\n",
    "* give the Spark driver 3G of memory and the executor 1G of memory.\n",
    "\n",
    "Having the parameters set, we call PyBDA\n",
    "\n",
    ".. code-block:: bash\n",
    "\n",
    "  pybda clustering pybda-usecase-clustering.config ``IP``\n",
    "\n",
    "The above command first executes the dimension reduction and then the clustering.\n",
    "After both ran, you should check the plots and statistics.\n",
    "\n",
    "Regression\n",
    "----------\n",
    "\n",
    "Here we show a small use case of how to regress a variable onto another set of variables exemplified\n",
    "on a small sample data set (``data/iris.tsv``). We assume you\n",
    "already set up the cluster for Spark (other check `here <./usage.html#spark>`__) with\n",
    "an ``IP`` address.\n",
    "\n",
    "Analysis\n",
    "........\n",
    "\n",
    "We will use a generalized linear regression model to establish a dependency between\n",
    "a response and a set of predictors. Apart to the GLM, you can choose from\n",
    "several regression methods\n",
    "\n",
    "* ``glm`` for `generalized linear regression models <https://en.wikipedia.org/wiki/Generalized_linear_model>`__,\n",
    "* ``gbm`` for stochastic `gradient boosting <https://en.wikipedia.org/wiki/Gradient_boosting>`__ ,\n",
    "* ``forest`` for `random forests <https://en.wikipedia.org/wiki/Random_forest>`__ .\n",
    "\n",
    "The config file we need to specify is in this case rather concise:\n",
    "\n",
    ".. literalinclude:: ../../data/pybda-usecase-regression.config\n",
    "  :caption: Contents of ``data/pybda-usecase-regression.config`` file\n",
    "  :name: pybda-usecase-regression.config\n",
    "\n",
    "In the config above we will do the following:\n",
    "\n",
    "* Use a generalized linear regression model with logit-link,\n",
    "* take as response the column called ``log_response``,\n",
    "* predict the response of for the same data set,\n",
    "* give the Spark driver 1G of memory and the executor 1G of memory,\n",
    "* set the Spark configuration variable ``spark.driver.maxResultSize`` to 1G\n",
    "\n",
    "Having the parameters set, we call PyBDA\n",
    "\n",
    ".. code-block:: bash\n",
    "\n",
    "  pybda dimension-reduction pybda-usecase-kpca.config IP\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
