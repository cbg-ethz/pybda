{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining multiple tasks at once\n",
    "\n",
    "Often, we are interested in combining several methods at once. This notebook shows how it is done! Here, we use dimension reduction + clustering + regression at the same time with **one**, simple config file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading our designated `pybda` environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(pybda) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "source ~/miniconda3/bin/activate pybda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run combinations of methods and models, we simply need to list them all in the same config file. We deposited one in the `data` folder of `pybda`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(pybda) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark: spark-submit\n",
      "infile: single_cell_imaging_data.tsv\n",
      "outfolder: results\n",
      "meta: meta_columns.tsv\n",
      "features: feature_columns.tsv\n",
      "dimension_reduction: pca, ica\n",
      "n_components: 5\n",
      "clustering: kmeans, gmm\n",
      "n_centers: 50, 100\n",
      "regression: forest, glm\n",
      "response: is_infected\n",
      "family: binomial\n",
      "sparkparams:\n",
      "  - \"--driver-memory=1G\"\n",
      "  - \"--executor-memory=1G\"\n",
      "debug: true\n",
      "(pybda) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cat pybda-usecase-dimred+clustering+regression.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The config file above we will do the following:\n",
    "\n",
    "* fit a PCA and ICA to `single_cell_imaging_data.tsv` using 5 components, \n",
    "* from the two results of PCA and ICA, do a $k$-means and a GMM clustering with 50, or 100, cluster centers, respectively,\n",
    "* regress the `response` column on the features in `feature_columns.tsv` using a random forest and a GLM,\n",
    "* use a `binomial` family variable,\n",
    "* give the Spark driver 1G of memory and the executor 1G of memory,\n",
    "* write the results to `results`,\n",
    "* print debug information.\n",
    "\n",
    "That's all we need to do!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then call `pybda` from the command line. Usually we would want to call `pybda` with a specific target (i.e., *clustering*, *dimension-reduction*, or *regression*) such that we do not run everything. However, in this case,\n",
    "where we **want** to execute everything, we call it with *run*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking command line arguments for method: regression\n",
      "Checking command line arguments for method: dimension_reduction\n",
      "Checking command line arguments for method: clustering\n",
      "\u001b[1;33m Printing rule tree:\n",
      " -> _ (, single_cell_imaging_data.tsv)\n",
      "\t -> regression (single_cell_imaging_data.tsv, results/2019_08_15/glm_from_single_cell_imaging_data.tsv)\n",
      "\t -> regression (single_cell_imaging_data.tsv, results/2019_08_15/forest_from_single_cell_imaging_data.tsv)\n",
      "\t -> dimension_reduction (single_cell_imaging_data.tsv, results/2019_08_15/ica_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/ica_from_single_cell_imaging_data.tsv, results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/ica_from_single_cell_imaging_data.tsv, results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data.tsv)\n",
      "\t -> dimension_reduction (single_cell_imaging_data.tsv, results/2019_08_15/pca_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/pca_from_single_cell_imaging_data.tsv, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/pca_from_single_cell_imaging_data.tsv, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data.tsv)\n",
      "\u001b[0m\n",
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n",
      "[2019-08-15 20:35:00,248 - WARNING - snakemake.logging]: Building DAG of jobs...\n",
      "\u001b[33mUsing shell: /bin/bash\u001b[0m\n",
      "[2019-08-15 20:35:00,265 - WARNING - snakemake.logging]: Using shell: /bin/bash\n",
      "\u001b[33mProvided cores: 1\u001b[0m\n",
      "[2019-08-15 20:35:00,265 - WARNING - snakemake.logging]: Provided cores: 1\n",
      "\u001b[33mRules claiming more threads will be scaled down.\u001b[0m\n",
      "[2019-08-15 20:35:00,265 - WARNING - snakemake.logging]: Rules claiming more threads will be scaled down.\n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t1\tforest\n",
      "\t1\tglm\n",
      "\t1\tgmm\n",
      "\t1\tica\n",
      "\t1\tkmeans\n",
      "\t1\tpca\n",
      "\t6\u001b[0m\n",
      "[2019-08-15 20:35:00,266 - WARNING - snakemake.logging]: Job counts:\n",
      "\tcount\tjobs\n",
      "\t1\tforest\n",
      "\t1\tglm\n",
      "\t1\tgmm\n",
      "\t1\tica\n",
      "\t1\tkmeans\n",
      "\t1\tpca\n",
      "\t6\n",
      "\u001b[32m\u001b[0m\n",
      "[2019-08-15 20:35:00,266 - INFO - snakemake.logging]: \n",
      "\u001b[32m[Thu Aug 15 20:35:00 2019]\u001b[0m\n",
      "[2019-08-15 20:35:00,267 - INFO - snakemake.logging]: [Thu Aug 15 20:35:00 2019]\n",
      "\u001b[32mrule pca:\n",
      "    input: single_cell_imaging_data.tsv\n",
      "    output: results/2019_08_15/pca_from_single_cell_imaging_data.tsv, results/2019_08_15/pca_from_single_cell_imaging_data-loadings.tsv, results/2019_08_15/pca_from_single_cell_imaging_data-plot\n",
      "    jobid: 0\u001b[0m\n",
      "[2019-08-15 20:35:00,267 - INFO - snakemake.logging]: rule pca:\n",
      "    input: single_cell_imaging_data.tsv\n",
      "    output: results/2019_08_15/pca_from_single_cell_imaging_data.tsv, results/2019_08_15/pca_from_single_cell_imaging_data-loadings.tsv, results/2019_08_15/pca_from_single_cell_imaging_data-plot\n",
      "    jobid: 0\n",
      "\u001b[32m\u001b[0m\n",
      "[2019-08-15 20:35:00,267 - INFO - snakemake.logging]: \n",
      "\u001b[1;33m Printing rule tree:\n",
      " -> _ (, single_cell_imaging_data.tsv)\n",
      "\t -> regression (single_cell_imaging_data.tsv, results/2019_08_15/glm_from_single_cell_imaging_data.tsv)\n",
      "\t -> regression (single_cell_imaging_data.tsv, results/2019_08_15/forest_from_single_cell_imaging_data.tsv)\n",
      "\t -> dimension_reduction (single_cell_imaging_data.tsv, results/2019_08_15/ica_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/ica_from_single_cell_imaging_data.tsv, results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/ica_from_single_cell_imaging_data.tsv, results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data.tsv)\n",
      "\t -> dimension_reduction (single_cell_imaging_data.tsv, results/2019_08_15/pca_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/pca_from_single_cell_imaging_data.tsv, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/pca_from_single_cell_imaging_data.tsv, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data.tsv)\n",
      "\u001b[0m\n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t1\tpca\n",
      "\t1\u001b[0m\n",
      "\u001b[1;33m Submitting job spark-submit --master local --driver-memory=1G --executor-memory=1G /home/simon/PROJECTS/pybda/pybda/pca.py 5 single_cell_imaging_data.tsv feature_columns.tsv results/2019_08_15/pca_from_single_cell_imaging_data > results/2019_08_15/pca_from_single_cell_imaging_data-spark.log \u001b[\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/daemon.py\", line 170, in manager\n",
      "  File \"/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/daemon.py\", line 73, in worker\n",
      "  File \"/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 397, in main\n",
      "    if read_int(infile) == SpecialLengths.END_OF_STREAM:\n",
      "  File \"/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\u001b[32m[Thu Aug 15 20:36:09 2019]\u001b[0m\n",
      "[2019-08-15 20:36:09,391 - INFO - snakemake.logging]: [Thu Aug 15 20:36:09 2019]\n",
      "\u001b[32mFinished job 0.\u001b[0m\n",
      "[2019-08-15 20:36:09,392 - INFO - snakemake.logging]: Finished job 0.\n",
      "\u001b[32m1 of 6 steps (17%) done\u001b[0m\n",
      "[2019-08-15 20:36:09,392 - INFO - snakemake.logging]: 1 of 6 steps (17%) done\n",
      "\u001b[32m\u001b[0m\n",
      "[2019-08-15 20:36:09,392 - INFO - snakemake.logging]: \n",
      "\u001b[32m[Thu Aug 15 20:36:09 2019]\u001b[0m\n",
      "[2019-08-15 20:36:09,392 - INFO - snakemake.logging]: [Thu Aug 15 20:36:09 2019]\n",
      "\u001b[32mrule ica:\n",
      "    input: single_cell_imaging_data.tsv\n",
      "    output: results/2019_08_15/ica_from_single_cell_imaging_data.tsv, results/2019_08_15/ica_from_single_cell_imaging_data-loadings.tsv, results/2019_08_15/ica_from_single_cell_imaging_data-plot\n",
      "    jobid: 3\u001b[0m\n",
      "[2019-08-15 20:36:09,393 - INFO - snakemake.logging]: rule ica:\n",
      "    input: single_cell_imaging_data.tsv\n",
      "    output: results/2019_08_15/ica_from_single_cell_imaging_data.tsv, results/2019_08_15/ica_from_single_cell_imaging_data-loadings.tsv, results/2019_08_15/ica_from_single_cell_imaging_data-plot\n",
      "    jobid: 3\n",
      "\u001b[32m\u001b[0m\n",
      "[2019-08-15 20:36:09,393 - INFO - snakemake.logging]: \n",
      "\u001b[1;33m Printing rule tree:\n",
      " -> _ (, single_cell_imaging_data.tsv)\n",
      "\t -> regression (single_cell_imaging_data.tsv, results/2019_08_15/glm_from_single_cell_imaging_data.tsv)\n",
      "\t -> regression (single_cell_imaging_data.tsv, results/2019_08_15/forest_from_single_cell_imaging_data.tsv)\n",
      "\t -> dimension_reduction (single_cell_imaging_data.tsv, results/2019_08_15/ica_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/ica_from_single_cell_imaging_data.tsv, results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/ica_from_single_cell_imaging_data.tsv, results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data.tsv)\n",
      "\t -> dimension_reduction (single_cell_imaging_data.tsv, results/2019_08_15/pca_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/pca_from_single_cell_imaging_data.tsv, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/pca_from_single_cell_imaging_data.tsv, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data.tsv)\n",
      "\u001b[0m\n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t1\tica\n",
      "\t1\u001b[0m\n",
      "\u001b[1;33m Submitting job spark-submit --master local --driver-memory=1G --executor-memory=1G /home/simon/PROJECTS/pybda/pybda/ica.py 5 single_cell_imaging_data.tsv feature_columns.tsv results/2019_08_15/ica_from_single_cell_imaging_data > results/2019_08_15/ica_from_single_cell_imaging_data-spark.log \u001b[\u001b[0m\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/mllib/linalg/__init__.py:291: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/daemon.py\", line 170, in manager\n",
      "  File \"/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/daemon.py\", line 73, in worker\n",
      "  File \"/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 397, in main\n",
      "    if read_int(infile) == SpecialLengths.END_OF_STREAM:\n",
      "  File \"/opt/local/spark/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\u001b[32m[Thu Aug 15 20:41:10 2019]\u001b[0m\n",
      "[2019-08-15 20:41:10,231 - INFO - snakemake.logging]: [Thu Aug 15 20:41:10 2019]\n",
      "\u001b[32mFinished job 3.\u001b[0m\n",
      "[2019-08-15 20:41:10,232 - INFO - snakemake.logging]: Finished job 3.\n",
      "\u001b[32m2 of 6 steps (33%) done\u001b[0m\n",
      "[2019-08-15 20:41:10,232 - INFO - snakemake.logging]: 2 of 6 steps (33%) done\n",
      "\u001b[32m\u001b[0m\n",
      "[2019-08-15 20:41:10,233 - INFO - snakemake.logging]: \n",
      "\u001b[32m[Thu Aug 15 20:41:10 2019]\u001b[0m\n",
      "[2019-08-15 20:41:10,233 - INFO - snakemake.logging]: [Thu Aug 15 20:41:10 2019]\n",
      "\u001b[32mrule kmeans:\n",
      "    input: results/2019_08_15/ica_from_single_cell_imaging_data.tsv, results/2019_08_15/pca_from_single_cell_imaging_data.tsv\n",
      "    output: results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data, results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data-profile.png, results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data-profile.pdf, results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data-profile.eps, results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data-profile.svg, results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data-profile.tsv, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data-profile.png, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data-profile.pdf, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data-profile.eps, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data-profile.svg, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data-profile.tsv, results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data-transformed-K50-clusters, results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data-transformed-K100-clusters, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data-transformed-K50-clusters, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data-transformed-K100-clusters\n",
      "    jobid: 1\u001b[0m\n",
      "[2019-08-15 20:41:10,233 - INFO - snakemake.logging]: rule kmeans:\n",
      "    input: results/2019_08_15/ica_from_single_cell_imaging_data.tsv, results/2019_08_15/pca_from_single_cell_imaging_data.tsv\n",
      "    output: results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data, results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data-profile.png, results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data-profile.pdf, results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data-profile.eps, results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data-profile.svg, results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data-profile.tsv, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data-profile.png, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data-profile.pdf, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data-profile.eps, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data-profile.svg, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data-profile.tsv, results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data-transformed-K50-clusters, results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data-transformed-K100-clusters, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data-transformed-K50-clusters, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data-transformed-K100-clusters\n",
      "    jobid: 1\n",
      "\u001b[32m\u001b[0m\n",
      "[2019-08-15 20:41:10,233 - INFO - snakemake.logging]: \n",
      "\u001b[1;33m Printing rule tree:\n",
      " -> _ (, single_cell_imaging_data.tsv)\n",
      "\t -> regression (single_cell_imaging_data.tsv, results/2019_08_15/glm_from_single_cell_imaging_data.tsv)\n",
      "\t -> regression (single_cell_imaging_data.tsv, results/2019_08_15/forest_from_single_cell_imaging_data.tsv)\n",
      "\t -> dimension_reduction (single_cell_imaging_data.tsv, results/2019_08_15/ica_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/ica_from_single_cell_imaging_data.tsv, results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/ica_from_single_cell_imaging_data.tsv, results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data.tsv)\n",
      "\t -> dimension_reduction (single_cell_imaging_data.tsv, results/2019_08_15/pca_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/pca_from_single_cell_imaging_data.tsv, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/pca_from_single_cell_imaging_data.tsv, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data.tsv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t1\tkmeans\n",
      "\t1\u001b[0m\n",
      "\u001b[1;33m Submitting job spark-submit --master local --driver-memory=1G --executor-memory=1G /home/simon/PROJECTS/pybda/pybda/kmeans.py 50,100 results/2019_08_15/ica_from_single_cell_imaging_data.tsv feature_columns.tsv results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data > results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data-spark.log \u001b[\u001b[0m\n",
      "\u001b[1;33m Submitting job spark-submit --master local --driver-memory=1G --executor-memory=1G /home/simon/PROJECTS/pybda/pybda/kmeans.py 50,100 results/2019_08_15/pca_from_single_cell_imaging_data.tsv feature_columns.tsv results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data > results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data-spark.log \u001b[\u001b[0m\n",
      "\u001b[32m[Thu Aug 15 20:42:10 2019]\u001b[0m\n",
      "[2019-08-15 20:42:10,216 - INFO - snakemake.logging]: [Thu Aug 15 20:42:10 2019]\n",
      "\u001b[32mFinished job 1.\u001b[0m\n",
      "[2019-08-15 20:42:10,216 - INFO - snakemake.logging]: Finished job 1.\n",
      "\u001b[32m3 of 6 steps (50%) done\u001b[0m\n",
      "[2019-08-15 20:42:10,216 - INFO - snakemake.logging]: 3 of 6 steps (50%) done\n",
      "\u001b[32m\u001b[0m\n",
      "[2019-08-15 20:42:10,217 - INFO - snakemake.logging]: \n",
      "\u001b[32m[Thu Aug 15 20:42:10 2019]\u001b[0m\n",
      "[2019-08-15 20:42:10,217 - INFO - snakemake.logging]: [Thu Aug 15 20:42:10 2019]\n",
      "\u001b[32mrule gmm:\n",
      "    input: results/2019_08_15/ica_from_single_cell_imaging_data.tsv, results/2019_08_15/pca_from_single_cell_imaging_data.tsv\n",
      "    output: results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data, results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data-profile.png, results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data-profile.pdf, results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data-profile.eps, results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data-profile.svg, results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data-profile.tsv, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data-profile.png, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data-profile.pdf, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data-profile.eps, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data-profile.svg, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data-profile.tsv, results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data-transformed-K50-components, results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data-transformed-K100-components, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data-transformed-K50-components, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data-transformed-K100-components\n",
      "    jobid: 5\u001b[0m\n",
      "[2019-08-15 20:42:10,217 - INFO - snakemake.logging]: rule gmm:\n",
      "    input: results/2019_08_15/ica_from_single_cell_imaging_data.tsv, results/2019_08_15/pca_from_single_cell_imaging_data.tsv\n",
      "    output: results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data, results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data-profile.png, results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data-profile.pdf, results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data-profile.eps, results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data-profile.svg, results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data-profile.tsv, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data-profile.png, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data-profile.pdf, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data-profile.eps, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data-profile.svg, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data-profile.tsv, results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data-transformed-K50-components, results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data-transformed-K100-components, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data-transformed-K50-components, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data-transformed-K100-components\n",
      "    jobid: 5\n",
      "\u001b[32m\u001b[0m\n",
      "[2019-08-15 20:42:10,217 - INFO - snakemake.logging]: \n",
      "\u001b[1;33m Printing rule tree:\n",
      " -> _ (, single_cell_imaging_data.tsv)\n",
      "\t -> regression (single_cell_imaging_data.tsv, results/2019_08_15/glm_from_single_cell_imaging_data.tsv)\n",
      "\t -> regression (single_cell_imaging_data.tsv, results/2019_08_15/forest_from_single_cell_imaging_data.tsv)\n",
      "\t -> dimension_reduction (single_cell_imaging_data.tsv, results/2019_08_15/ica_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/ica_from_single_cell_imaging_data.tsv, results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/ica_from_single_cell_imaging_data.tsv, results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data.tsv)\n",
      "\t -> dimension_reduction (single_cell_imaging_data.tsv, results/2019_08_15/pca_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/pca_from_single_cell_imaging_data.tsv, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/pca_from_single_cell_imaging_data.tsv, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data.tsv)\n",
      "\u001b[0m\n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t1\tgmm\n",
      "\t1\u001b[0m\n",
      "\u001b[1;33m Submitting job spark-submit --master local --driver-memory=1G --executor-memory=1G /home/simon/PROJECTS/pybda/pybda/gmm.py 50,100 results/2019_08_15/ica_from_single_cell_imaging_data.tsv feature_columns.tsv results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data > results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data-spark.log \u001b[\u001b[0m\n",
      "\u001b[1;33m Submitting job spark-submit --master local --driver-memory=1G --executor-memory=1G /home/simon/PROJECTS/pybda/pybda/gmm.py 50,100 results/2019_08_15/pca_from_single_cell_imaging_data.tsv feature_columns.tsv results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data > results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data-spark.log \u001b[\u001b[0m\n",
      "\u001b[32m[Thu Aug 15 20:45:47 2019]\u001b[0m\n",
      "[2019-08-15 20:45:47,512 - INFO - snakemake.logging]: [Thu Aug 15 20:45:47 2019]\n",
      "\u001b[32mFinished job 5.\u001b[0m\n",
      "[2019-08-15 20:45:47,512 - INFO - snakemake.logging]: Finished job 5.\n",
      "\u001b[32m4 of 6 steps (67%) done\u001b[0m\n",
      "[2019-08-15 20:45:47,512 - INFO - snakemake.logging]: 4 of 6 steps (67%) done\n",
      "\u001b[32m\u001b[0m\n",
      "[2019-08-15 20:45:47,513 - INFO - snakemake.logging]: \n",
      "\u001b[32m[Thu Aug 15 20:45:47 2019]\u001b[0m\n",
      "[2019-08-15 20:45:47,513 - INFO - snakemake.logging]: [Thu Aug 15 20:45:47 2019]\n",
      "\u001b[32mrule forest:\n",
      "    input: single_cell_imaging_data.tsv\n",
      "    output: results/2019_08_15/forest_from_single_cell_imaging_data-statistics.tsv\n",
      "    jobid: 4\u001b[0m\n",
      "[2019-08-15 20:45:47,513 - INFO - snakemake.logging]: rule forest:\n",
      "    input: single_cell_imaging_data.tsv\n",
      "    output: results/2019_08_15/forest_from_single_cell_imaging_data-statistics.tsv\n",
      "    jobid: 4\n",
      "\u001b[32m\u001b[0m\n",
      "[2019-08-15 20:45:47,513 - INFO - snakemake.logging]: \n",
      "\u001b[1;33m Printing rule tree:\n",
      " -> _ (, single_cell_imaging_data.tsv)\n",
      "\t -> regression (single_cell_imaging_data.tsv, results/2019_08_15/glm_from_single_cell_imaging_data.tsv)\n",
      "\t -> regression (single_cell_imaging_data.tsv, results/2019_08_15/forest_from_single_cell_imaging_data.tsv)\n",
      "\t -> dimension_reduction (single_cell_imaging_data.tsv, results/2019_08_15/ica_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/ica_from_single_cell_imaging_data.tsv, results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/ica_from_single_cell_imaging_data.tsv, results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data.tsv)\n",
      "\t -> dimension_reduction (single_cell_imaging_data.tsv, results/2019_08_15/pca_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/pca_from_single_cell_imaging_data.tsv, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/pca_from_single_cell_imaging_data.tsv, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data.tsv)\n",
      "\u001b[0m\n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t1\tforest\n",
      "\t1\u001b[0m\n",
      "\u001b[1;33m Submitting job spark-submit --master local --driver-memory=1G --executor-memory=1G /home/simon/PROJECTS/pybda/pybda/forest.py --predict None single_cell_imaging_data.tsv meta_columns.tsv feature_columns.tsv is_infected binomial results/2019_08_15/forest_from_single_cell_imaging_data > results/2019_08_15/forest_from_single_cell_imaging_data-spark.log \u001b[\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[Thu Aug 15 20:46:15 2019]\u001b[0m\n",
      "[2019-08-15 20:46:15,981 - INFO - snakemake.logging]: [Thu Aug 15 20:46:15 2019]\n",
      "\u001b[32mFinished job 4.\u001b[0m\n",
      "[2019-08-15 20:46:15,981 - INFO - snakemake.logging]: Finished job 4.\n",
      "\u001b[32m5 of 6 steps (83%) done\u001b[0m\n",
      "[2019-08-15 20:46:15,982 - INFO - snakemake.logging]: 5 of 6 steps (83%) done\n",
      "\u001b[32m\u001b[0m\n",
      "[2019-08-15 20:46:15,982 - INFO - snakemake.logging]: \n",
      "\u001b[32m[Thu Aug 15 20:46:15 2019]\u001b[0m\n",
      "[2019-08-15 20:46:15,982 - INFO - snakemake.logging]: [Thu Aug 15 20:46:15 2019]\n",
      "\u001b[32mrule glm:\n",
      "    input: single_cell_imaging_data.tsv\n",
      "    output: results/2019_08_15/glm_from_single_cell_imaging_data-table.tsv, results/2019_08_15/glm_from_single_cell_imaging_data-statistics.tsv\n",
      "    jobid: 2\u001b[0m\n",
      "[2019-08-15 20:46:15,982 - INFO - snakemake.logging]: rule glm:\n",
      "    input: single_cell_imaging_data.tsv\n",
      "    output: results/2019_08_15/glm_from_single_cell_imaging_data-table.tsv, results/2019_08_15/glm_from_single_cell_imaging_data-statistics.tsv\n",
      "    jobid: 2\n",
      "\u001b[32m\u001b[0m\n",
      "[2019-08-15 20:46:15,982 - INFO - snakemake.logging]: \n",
      "\u001b[1;33m Printing rule tree:\n",
      " -> _ (, single_cell_imaging_data.tsv)\n",
      "\t -> regression (single_cell_imaging_data.tsv, results/2019_08_15/glm_from_single_cell_imaging_data.tsv)\n",
      "\t -> regression (single_cell_imaging_data.tsv, results/2019_08_15/forest_from_single_cell_imaging_data.tsv)\n",
      "\t -> dimension_reduction (single_cell_imaging_data.tsv, results/2019_08_15/ica_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/ica_from_single_cell_imaging_data.tsv, results/2019_08_15/gmm_from_ica_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/ica_from_single_cell_imaging_data.tsv, results/2019_08_15/kmeans_from_ica_from_single_cell_imaging_data.tsv)\n",
      "\t -> dimension_reduction (single_cell_imaging_data.tsv, results/2019_08_15/pca_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/pca_from_single_cell_imaging_data.tsv, results/2019_08_15/gmm_from_pca_from_single_cell_imaging_data.tsv)\n",
      "\t\t -> clustering (results/2019_08_15/pca_from_single_cell_imaging_data.tsv, results/2019_08_15/kmeans_from_pca_from_single_cell_imaging_data.tsv)\n",
      "\u001b[0m\n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t1\tglm\n",
      "\t1\u001b[0m\n",
      "\u001b[1;33m Submitting job spark-submit --master local --driver-memory=1G --executor-memory=1G /home/simon/PROJECTS/pybda/pybda/glm.py --predict None single_cell_imaging_data.tsv meta_columns.tsv feature_columns.tsv is_infected binomial results/2019_08_15/glm_from_single_cell_imaging_data > results/2019_08_15/glm_from_single_cell_imaging_data-spark.log \u001b[\u001b[0m\n",
      "\u001b[32m[Thu Aug 15 20:46:45 2019]\u001b[0m\n",
      "[2019-08-15 20:46:45,434 - INFO - snakemake.logging]: [Thu Aug 15 20:46:45 2019]\n",
      "\u001b[32mFinished job 2.\u001b[0m\n",
      "[2019-08-15 20:46:45,434 - INFO - snakemake.logging]: Finished job 2.\n",
      "\u001b[32m6 of 6 steps (100%) done\u001b[0m\n",
      "[2019-08-15 20:46:45,434 - INFO - snakemake.logging]: 6 of 6 steps (100%) done\n",
      "\u001b[33mComplete log: /home/simon/PROJECTS/pybda/data/.snakemake/log/2019-08-15T203500.185751.snakemake.log\u001b[0m\n",
      "[2019-08-15 20:46:45,435 - WARNING - snakemake.logging]: Complete log: /home/simon/PROJECTS/pybda/data/.snakemake/log/2019-08-15T203500.185751.snakemake.log\n",
      "(pybda) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "pybda run pybda-usecase-dimred+clustering+regression.config local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! After ``pybda`` finishes we should check which files we got. For instance, this we wanted to use a PCA as input for $k$-means, two of the created files would be:\n",
    "- `pca_from_single_cell_imaging_data.tsv` and\n",
    "- `kmeans_frompca_from_single_cell_imaging_data.tsv` and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(pybda) drwxrwxr-x 4    4096 Aug 15 20:42 \u001b[37;45m\u001b[Kkmeans_from_pca_from_single_cell_imaging_data\u001b[m\u001b[K\n",
      "-rw-rw-r-- 1   33389 Aug 15 20:42 \u001b[37;45m\u001b[Kkmeans_from_pca_from_single_cell_imaging_data\u001b[m\u001b[K-cluster_sizes-histogram.eps\n",
      "-rw-rw-r-- 1   10937 Aug 15 20:42 \u001b[37;45m\u001b[Kkmeans_from_pca_from_single_cell_imaging_data\u001b[m\u001b[K-cluster_sizes-histogram.pdf\n",
      "-rw-rw-r-- 1   94000 Aug 15 20:42 \u001b[37;45m\u001b[Kkmeans_from_pca_from_single_cell_imaging_data\u001b[m\u001b[K-cluster_sizes-histogram.png\n",
      "-rw-rw-r-- 1   43122 Aug 15 20:42 \u001b[37;45m\u001b[Kkmeans_from_pca_from_single_cell_imaging_data\u001b[m\u001b[K-cluster_sizes-histogram.svg\n",
      "-rw-rw-r-- 1    6668 Aug 15 20:42 \u001b[37;45m\u001b[Kkmeans_from_pca_from_single_cell_imaging_data\u001b[m\u001b[K.log\n",
      "-rw-rw-r-- 1   20587 Aug 15 20:42 \u001b[37;45m\u001b[Kkmeans_from_pca_from_single_cell_imaging_data\u001b[m\u001b[K-profile.eps\n",
      "-rw-rw-r-- 1   11827 Aug 15 20:42 \u001b[37;45m\u001b[Kkmeans_from_pca_from_single_cell_imaging_data\u001b[m\u001b[K-profile.pdf\n",
      "-rw-rw-r-- 1  223485 Aug 15 20:42 \u001b[37;45m\u001b[Kkmeans_from_pca_from_single_cell_imaging_data\u001b[m\u001b[K-profile.png\n",
      "-rw-rw-r-- 1   28460 Aug 15 20:42 \u001b[37;45m\u001b[Kkmeans_from_pca_from_single_cell_imaging_data\u001b[m\u001b[K-profile.svg\n",
      "-rw-rw-r-- 1     220 Aug 15 20:42 \u001b[37;45m\u001b[Kkmeans_from_pca_from_single_cell_imaging_data\u001b[m\u001b[K-profile.tsv\n",
      "-rw-rw-r-- 1  893509 Aug 15 20:42 \u001b[37;45m\u001b[Kkmeans_from_pca_from_single_cell_imaging_data\u001b[m\u001b[K-spark.log\n",
      "-rw-rw-r-- 1      34 Aug 15 20:41 \u001b[37;45m\u001b[Kkmeans_from_pca_from_single_cell_imaging_data\u001b[m\u001b[K-total_sse.tsv\n",
      "drwxrwxr-x 2    4096 Aug 15 20:42 \u001b[37;45m\u001b[Kkmeans_from_pca_from_single_cell_imaging_data\u001b[m\u001b[K-transformed-K100-clusters\n",
      "drwxrwxr-x 2    4096 Aug 15 20:42 \u001b[37;45m\u001b[Kkmeans_from_pca_from_single_cell_imaging_data\u001b[m\u001b[K-transformed-K50-clusters\n",
      "(pybda) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cd results\n",
    "ls -lgG * | grep kmeans_from_pca_from_single_cell_imaging_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we should always check log files let's have a look at one. For instance, since we wanted to use ICA and afterwards $k$-means we can check if ``pybda`` did everything correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-15 20:41:17,066 - INFO - pybda.spark.features]: Casting columns to double.\n",
      "[2019-08-15 20:41:17,351 - INFO - pybda.spark.features]: Assembling column to feature vector\n",
      "[2019-08-15 20:41:17,351 - INFO - pybda.spark.features]: Found columns with prefix f_ from previous computation: f_0\tf_1\tf_2\tf_3\tf_4. Preferring these columns as features\n",
      "[2019-08-15 20:41:17,455 - INFO - pybda.spark.features]: Dropping redundant columns\n",
      "[2019-08-15 20:41:18,203 - INFO - pybda.spark.dataframe]: Using data with n=10000 and p=5\n",
      "(pybda) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cat */kmeans_from_ica_from_single_cell_imaging_data.log | tail -n40 | head -n5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we see that ``pybda`` when executing the $k$-means realized that we used dimension reduction before (`Found columns with prefix f_ from previous computation`) and thus uses these for the clustering and not the original data. This should also be true, for instance, for PCA and the Gaussian mixture model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-15 20:44:02,430 - INFO - pybda.io.io]: Reading tsv: results/2019_08_15/pca_from_single_cell_imaging_data.tsv\n",
      "[2019-08-15 20:44:05,672 - INFO - pybda.spark.features]: Found columns with prefix f_ from previous computation: f_0\tf_1\tf_2\tf_3\tf_4.\n",
      "Preferring these columns as features/\n",
      "[2019-08-15 20:44:05,672 - INFO - pybda.spark.features]: Casting columns to double.\n",
      "[2019-08-15 20:44:05,946 - INFO - pybda.spark.features]: Assembling column to feature vector\n",
      "(pybda) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cat */gmm_from_pca_from_single_cell_imaging_data.log | tail -n40 | head -n5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
