{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering and mixture models\n",
    "\n",
    "\n",
    "The following `notebook` shows how PyBDA can be used for a simple clustering task. We use the `iris` data, because clustering it is fairly easy and we can use it as a check if everything worked out nicely. We'll use a $k$-means clustering and compare it to a Gaussian mixture model (GMM). The $k$-means has fairly stringent assumptions about the data, i.e. spherical Gaussians, while the GMM estimates the variances from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by activating our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(pybda) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "source ~/miniconda3/bin/activate pybda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do two clusterings, we merely need to set up a short config file with the two method names. We already provided a file that could do the trick for us in the `data` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(pybda) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark: spark-submit\n",
      "infile: iris.tsv\n",
      "outfolder: results\n",
      "meta: iris_meta_columns.tsv\n",
      "features: iris_feature_columns.tsv\n",
      "clustering: kmeans,gmm\n",
      "n_centers: 3, 5, 10\n",
      "sparkparams:\n",
      "  - \"--driver-memory=1G\"\n",
      "  - \"--executor-memory=1G\"\n",
      "debug: true\n",
      "(pybda) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cat pybda-usecase-clustering.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the config above we will do the following:\n",
    "\n",
    "* do clustering/mixture model with 3, 5 and 10 cluster centers on the features provided in `iris_feature_columns.tsv`,\n",
    "* give the Spark driver 1G of memory and the executor 1G of memory,\n",
    "* write the results to `results`,\n",
    "* print debug information.\n",
    "\n",
    "This totals 6 clusterings from two different methods with minimal coding effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the parameters set, we can call PyBDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n",
      "[2019-08-08 22:22:30,284 - WARNING - snakemake.logging]: Building DAG of jobs...\n",
      "\u001b[33mUsing shell: /bin/bash\u001b[0m\n",
      "[2019-08-08 22:22:30,296 - WARNING - snakemake.logging]: Using shell: /bin/bash\n",
      "\u001b[33mProvided cores: 1\u001b[0m\n",
      "[2019-08-08 22:22:30,296 - WARNING - snakemake.logging]: Provided cores: 1\n",
      "\u001b[33mRules claiming more threads will be scaled down.\u001b[0m\n",
      "[2019-08-08 22:22:30,296 - WARNING - snakemake.logging]: Rules claiming more threads will be scaled down.\n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t1\tgmm\n",
      "\t1\tkmeans\n",
      "\t2\u001b[0m\n",
      "[2019-08-08 22:22:30,297 - WARNING - snakemake.logging]: Job counts:\n",
      "\tcount\tjobs\n",
      "\t1\tgmm\n",
      "\t1\tkmeans\n",
      "\t2\n",
      "\u001b[32m\u001b[0m\n",
      "[2019-08-08 22:22:30,297 - INFO - snakemake.logging]: \n",
      "\u001b[32m[Thu Aug  8 22:22:30 2019]\u001b[0m\n",
      "[2019-08-08 22:22:30,297 - INFO - snakemake.logging]: [Thu Aug  8 22:22:30 2019]\n",
      "\u001b[32mrule gmm:\n",
      "    input: iris.tsv\n",
      "    output: results/2019_08_08/gmm_from_iris, results/2019_08_08/gmm_from_iris-profile.png, results/2019_08_08/gmm_from_iris-profile.pdf, results/2019_08_08/gmm_from_iris-profile.eps, results/2019_08_08/gmm_from_iris-profile.svg, results/2019_08_08/gmm_from_iris-profile.tsv, results/2019_08_08/gmm_from_iris-transformed-K3-components, results/2019_08_08/gmm_from_iris-transformed-K5-components, results/2019_08_08/gmm_from_iris-transformed-K10-components\n",
      "    jobid: 0\u001b[0m\n",
      "[2019-08-08 22:22:30,297 - INFO - snakemake.logging]: rule gmm:\n",
      "    input: iris.tsv\n",
      "    output: results/2019_08_08/gmm_from_iris, results/2019_08_08/gmm_from_iris-profile.png, results/2019_08_08/gmm_from_iris-profile.pdf, results/2019_08_08/gmm_from_iris-profile.eps, results/2019_08_08/gmm_from_iris-profile.svg, results/2019_08_08/gmm_from_iris-profile.tsv, results/2019_08_08/gmm_from_iris-transformed-K3-components, results/2019_08_08/gmm_from_iris-transformed-K5-components, results/2019_08_08/gmm_from_iris-transformed-K10-components\n",
      "    jobid: 0\n",
      "\u001b[32m\u001b[0m\n",
      "[2019-08-08 22:22:30,297 - INFO - snakemake.logging]: \n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t1\tgmm\n",
      "\t1\u001b[0m\n",
      "\u001b[1;33m Submitting job spark-submit --master local --driver-memory=1G --executor-memory=1G /home/simon/PROJECTS/pybda/pybda/gmm.py 3,5,10 iris.tsv iris_feature_columns.tsv results/2019_08_08/gmm_from_iris > results/2019_08_08/gmm_from_iris-spark.log \u001b[\u001b[0m\n",
      "\u001b[1;33m Printing rule tree:\n",
      " -> _ (, iris.tsv)\n",
      "\t -> clustering (iris.tsv, results/2019_08_08/gmm_from_iris.tsv)\n",
      "\t -> clustering (iris.tsv, results/2019_08_08/kmeans_from_iris.tsv)\n",
      "\u001b[0m\n",
      "\u001b[32m[Thu Aug  8 22:22:59 2019]\u001b[0m\n",
      "[2019-08-08 22:22:59,844 - INFO - snakemake.logging]: [Thu Aug  8 22:22:59 2019]\n",
      "\u001b[32mFinished job 0.\u001b[0m\n",
      "[2019-08-08 22:22:59,844 - INFO - snakemake.logging]: Finished job 0.\n",
      "\u001b[32m1 of 2 steps (50%) done\u001b[0m\n",
      "[2019-08-08 22:22:59,845 - INFO - snakemake.logging]: 1 of 2 steps (50%) done\n",
      "\u001b[32m\u001b[0m\n",
      "[2019-08-08 22:22:59,847 - INFO - snakemake.logging]: \n",
      "\u001b[32m[Thu Aug  8 22:22:59 2019]\u001b[0m\n",
      "[2019-08-08 22:22:59,848 - INFO - snakemake.logging]: [Thu Aug  8 22:22:59 2019]\n",
      "\u001b[32mrule kmeans:\n",
      "    input: iris.tsv\n",
      "    output: results/2019_08_08/kmeans_from_iris, results/2019_08_08/kmeans_from_iris-profile.png, results/2019_08_08/kmeans_from_iris-profile.pdf, results/2019_08_08/kmeans_from_iris-profile.eps, results/2019_08_08/kmeans_from_iris-profile.svg, results/2019_08_08/kmeans_from_iris-profile.tsv, results/2019_08_08/kmeans_from_iris-transformed-K3-clusters, results/2019_08_08/kmeans_from_iris-transformed-K5-clusters, results/2019_08_08/kmeans_from_iris-transformed-K10-clusters\n",
      "    jobid: 1\u001b[0m\n",
      "[2019-08-08 22:22:59,848 - INFO - snakemake.logging]: rule kmeans:\n",
      "    input: iris.tsv\n",
      "    output: results/2019_08_08/kmeans_from_iris, results/2019_08_08/kmeans_from_iris-profile.png, results/2019_08_08/kmeans_from_iris-profile.pdf, results/2019_08_08/kmeans_from_iris-profile.eps, results/2019_08_08/kmeans_from_iris-profile.svg, results/2019_08_08/kmeans_from_iris-profile.tsv, results/2019_08_08/kmeans_from_iris-transformed-K3-clusters, results/2019_08_08/kmeans_from_iris-transformed-K5-clusters, results/2019_08_08/kmeans_from_iris-transformed-K10-clusters\n",
      "    jobid: 1\n",
      "\u001b[32m\u001b[0m\n",
      "[2019-08-08 22:22:59,850 - INFO - snakemake.logging]: \n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t1\tkmeans\n",
      "\t1\u001b[0m\n",
      "\u001b[1;33m Submitting job spark-submit --master local --driver-memory=1G --executor-memory=1G /home/simon/PROJECTS/pybda/pybda/kmeans.py 3,5,10 iris.tsv iris_feature_columns.tsv results/2019_08_08/kmeans_from_iris > results/2019_08_08/kmeans_from_iris-spark.log \u001b[\u001b[0m\n",
      "\u001b[1;33m Printing rule tree:\n",
      " -> _ (, iris.tsv)\n",
      "\t -> clustering (iris.tsv, results/2019_08_08/gmm_from_iris.tsv)\n",
      "\u001b[32m[Thu Aug  8 22:23:31 2019]\u001b[0m\n",
      "[2019-08-08 22:23:31,590 - INFO - snakemake.logging]: [Thu Aug  8 22:23:31 2019]\n",
      "\u001b[32mFinished job 1.\u001b[0m\n",
      "[2019-08-08 22:23:31,590 - INFO - snakemake.logging]: Finished job 1.\n",
      "\u001b[32m2 of 2 steps (100%) done\u001b[0m\n",
      "[2019-08-08 22:23:31,590 - INFO - snakemake.logging]: 2 of 2 steps (100%) done\n",
      "\u001b[33mComplete log: /home/simon/PROJECTS/pybda/data/.snakemake/log/2019-08-08T222230.229745.snakemake.log\u001b[0m\n",
      "[2019-08-08 22:23:31,590 - WARNING - snakemake.logging]: Complete log: /home/simon/PROJECTS/pybda/data/.snakemake/log/2019-08-08T222230.229745.snakemake.log\n",
      "Exception ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "(pybda) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "pybda clustering pybda-usecase-clustering.config local | head -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call automatically executes the jobs defined in the config. After both ran, we should check the plots and statistics. Let's see what we got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(pybda) total 3196\n",
      "drwxrwxr-x 5    4096 Aug  8 22:22 \u001b[0m\u001b[01;34mgmm_from_iris\u001b[0m\n",
      "-rw-rw-r-- 1   41630 Aug  8 22:22 gmm_from_iris-cluster_sizes-histogram.eps\n",
      "-rw-rw-r-- 1   11913 Aug  8 22:22 gmm_from_iris-cluster_sizes-histogram.pdf\n",
      "-rw-rw-r-- 1   94191 Aug  8 22:22 \u001b[01;35mgmm_from_iris-cluster_sizes-histogram.png\u001b[0m\n",
      "-rw-rw-r-- 1   54900 Aug  8 22:22 \u001b[01;35mgmm_from_iris-cluster_sizes-histogram.svg\u001b[0m\n",
      "-rw-rw-r-- 1    6332 Aug  8 22:22 gmm_from_iris.log\n",
      "-rw-rw-r-- 1   22803 Aug  8 22:22 gmm_from_iris-profile.eps\n",
      "-rw-rw-r-- 1   13040 Aug  8 22:22 gmm_from_iris-profile.pdf\n",
      "-rw-rw-r-- 1  218232 Aug  8 22:22 \u001b[01;35mgmm_from_iris-profile.png\u001b[0m\n",
      "-rw-rw-r-- 1   31619 Aug  8 22:22 \u001b[01;35mgmm_from_iris-profile.svg\u001b[0m\n",
      "-rw-rw-r-- 1     137 Aug  8 22:22 gmm_from_iris-profile.tsv\n",
      "-rw-rw-r-- 1 1288436 Aug  8 22:22 gmm_from_iris-spark.log\n",
      "drwxrwxr-x 2    4096 Aug  8 22:22 \u001b[01;34mgmm_from_iris-transformed-K10-components\u001b[0m\n",
      "drwxrwxr-x 2    4096 Aug  8 22:22 \u001b[01;34mgmm_from_iris-transformed-K3-components\u001b[0m\n",
      "drwxrwxr-x 2    4096 Aug  8 22:22 \u001b[01;34mgmm_from_iris-transformed-K5-components\u001b[0m\n",
      "drwxrwxr-x 5    4096 Aug  8 22:23 \u001b[01;34mkmeans_from_iris\u001b[0m\n",
      "-rw-rw-r-- 1   42077 Aug  8 22:23 kmeans_from_iris-cluster_sizes-histogram.eps\n",
      "-rw-rw-r-- 1   12123 Aug  8 22:23 kmeans_from_iris-cluster_sizes-histogram.pdf\n",
      "-rw-rw-r-- 1   95647 Aug  8 22:23 \u001b[01;35mkmeans_from_iris-cluster_sizes-histogram.png\u001b[0m\n",
      "-rw-rw-r-- 1   55531 Aug  8 22:23 \u001b[01;35mkmeans_from_iris-cluster_sizes-histogram.svg\u001b[0m\n",
      "-rw-rw-r-- 1    6699 Aug  8 22:23 kmeans_from_iris.log\n",
      "-rw-rw-r-- 1   21507 Aug  8 22:23 kmeans_from_iris-profile.eps\n",
      "-rw-rw-r-- 1   11786 Aug  8 22:23 kmeans_from_iris-profile.pdf\n",
      "-rw-rw-r-- 1  211541 Aug  8 22:23 \u001b[01;35mkmeans_from_iris-profile.png\u001b[0m\n",
      "-rw-rw-r-- 1   29644 Aug  8 22:23 \u001b[01;35mkmeans_from_iris-profile.svg\u001b[0m\n",
      "-rw-rw-r-- 1     296 Aug  8 22:23 kmeans_from_iris-profile.tsv\n",
      "-rw-rw-r-- 1  920657 Aug  8 22:23 kmeans_from_iris-spark.log\n",
      "-rw-rw-r-- 1      33 Aug  8 22:23 kmeans_from_iris-total_sse.tsv\n",
      "drwxrwxr-x 2    4096 Aug  8 22:23 \u001b[01;34mkmeans_from_iris-transformed-K10-clusters\u001b[0m\n",
      "drwxrwxr-x 2    4096 Aug  8 22:23 \u001b[01;34mkmeans_from_iris-transformed-K3-clusters\u001b[0m\n",
      "drwxrwxr-x 2    4096 Aug  8 22:23 \u001b[01;34mkmeans_from_iris-transformed-K5-clusters\u001b[0m\n",
      "(pybda) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cd results\n",
    "ls -lgG *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, finally let's check how many clusters/components are recommended for each method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k\twithin_cluster_variance\texplained_variance\ttotal_variance\tBIC\t\n",
      "3\t78.85566447695781\t0.8842690519576577\t681.3705911067716\t143.99392330020913\t\n",
      "5\t46.71230004910447\t0.931443621637341\t681.3705911067716\t151.93564122512583\t\n",
      "10\t32.49992444218044\t0.9523021321049536\t681.3705911067716\t237.93597150012693\t\n",
      "(pybda) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cat */kmeans_from_iris-profile.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k\tloglik\tBIC\t\n",
      "3\t-189.53852954643244\t599.5450120331002\t\n",
      "5\t-154.60572954901806\t679.998470861159\t\n",
      "10\t-50.516420858075136\t847.6175005364923\t\n",
      "(pybda) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cat */gmm_from_iris-profile.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in both cases the optimal number would be three! Just as expected from the `iris` data. Nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's plenty of other files and plots available to check out, though! For instance, we should _always_ look at the `log` files we created to check some params, and what we actually computed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-08 22:22:33,019 - INFO - pybda.spark_session]: Initializing pyspark session\n",
      "[2019-08-08 22:22:34,089 - INFO - pybda.spark_session]: Config: spark.master, value: local\n",
      "[2019-08-08 22:22:34,089 - INFO - pybda.spark_session]: Config: spark.driver.memory, value: 1G\n",
      "[2019-08-08 22:22:34,089 - INFO - pybda.spark_session]: Config: spark.rdd.compress, value: True\n",
      "[2019-08-08 22:22:34,089 - INFO - pybda.spark_session]: Config: spark.serializer.objectStreamReset, value: 100\n",
      "[2019-08-08 22:22:34,089 - INFO - pybda.spark_session]: Config: spark.app.name, value: gmm.py\n",
      "[2019-08-08 22:22:34,089 - INFO - pybda.spark_session]: Config: spark.executor.id, value: driver\n",
      "[2019-08-08 22:22:34,089 - INFO - pybda.spark_session]: Config: spark.driver.port, value: 37957\n",
      "[2019-08-08 22:22:34,089 - INFO - pybda.spark_session]: Config: spark.app.id, value: local-1565295753672\n",
      "[2019-08-08 22:22:34,089 - INFO - pybda.spark_session]: Config: spark.submit.deployMode, value: client\n",
      "[2019-08-08 22:22:34,089 - INFO - pybda.spark_session]: Config: spark.driver.host, value: 192.168.1.33\n",
      "[2019-08-08 22:22:34,089 - INFO - pybda.spark_session]: Openened spark context at: Thu Aug  8 22:22:34 2019\n",
      "[2019-08-08 22:22:34,101 - INFO - pybda.io.io]: Reading tsv: iris.tsv\n",
      "[2019-08-08 22:22:37,724 - INFO - pybda.spark.features]: Casting columns to double.\n",
      "[2019-08-08 22:22:37,974 - INFO - pybda.spark.features]: Assembling column to feature vector\n",
      "[2019-08-08 22:22:38,080 - INFO - pybda.spark.features]: Dropping redundant columns\n",
      "[2019-08-08 22:22:38,816 - INFO - pybda.spark.dataframe]: Using data with n=150 and p=4\n",
      "[2019-08-08 22:22:38,822 - INFO - __main__]: Clustering with K: 3\n",
      "[2019-08-08 22:22:42,892 - INFO - pybda.decorators]: function: '_fit_one' took: 4.0702 sec\n",
      "[2019-08-08 22:22:42,893 - INFO - pybda.fit.clustering_fit]: Writing cluster fit to: results/2019_08_08/gmm_from_iris/gmm-fit-K3\n",
      "[2019-08-08 22:22:43,828 - INFO - pybda.fit.clustering_fit]: Writing cluster size file to: results/2019_08_08/gmm_from_iris/gmm-fit-K3_cluster_sizes.tsv\n",
      "[2019-08-08 22:22:43,833 - INFO - pybda.fit.gmm_fit]: Writing cluster weights/means/variances\n",
      "[2019-08-08 22:22:43,982 - INFO - pybda.fit.gmm_fit]: Writing LogLik and BIC to: results/2019_08_08/gmm_from_iris/gmm-fit-K3_statistics.tsv\n",
      "[2019-08-08 22:22:43,982 - INFO - __main__]: Clustering with K: 5\n",
      "[2019-08-08 22:22:46,301 - INFO - pybda.decorators]: function: '_fit_one' took: 2.3183 sec\n",
      "[2019-08-08 22:22:46,301 - INFO - pybda.fit.clustering_fit]: Writing cluster fit to: results/2019_08_08/gmm_from_iris/gmm-fit-K5\n",
      "[2019-08-08 22:22:46,485 - INFO - pybda.fit.clustering_fit]: Writing cluster size file to: results/2019_08_08/gmm_from_iris/gmm-fit-K5_cluster_sizes.tsv\n",
      "[2019-08-08 22:22:46,488 - INFO - pybda.fit.gmm_fit]: Writing cluster weights/means/variances\n",
      "[2019-08-08 22:22:46,590 - INFO - pybda.fit.gmm_fit]: Writing LogLik and BIC to: results/2019_08_08/gmm_from_iris/gmm-fit-K5_statistics.tsv\n",
      "[2019-08-08 22:22:46,590 - INFO - __main__]: Clustering with K: 10\n",
      "[2019-08-08 22:22:48,165 - INFO - pybda.decorators]: function: '_fit_one' took: 1.5755 sec\n",
      "[2019-08-08 22:22:48,166 - INFO - pybda.fit.clustering_fit]: Writing cluster fit to: results/2019_08_08/gmm_from_iris/gmm-fit-K10\n",
      "[2019-08-08 22:22:48,347 - INFO - pybda.fit.clustering_fit]: Writing cluster size file to: results/2019_08_08/gmm_from_iris/gmm-fit-K10_cluster_sizes.tsv\n",
      "[2019-08-08 22:22:48,352 - INFO - pybda.fit.gmm_fit]: Writing cluster weights/means/variances\n",
      "[2019-08-08 22:22:48,452 - INFO - pybda.fit.gmm_fit]: Writing LogLik and BIC to: results/2019_08_08/gmm_from_iris/gmm-fit-K10_statistics.tsv\n",
      "[2019-08-08 22:22:48,452 - INFO - pybda.fit.clustering_fit_profile]: Writing fit profile to results/2019_08_08/gmm_from_iris-profile.tsv\n",
      "[2019-08-08 22:22:48,454 - INFO - pybda.fit.clustering_fit_profile]: 3\n",
      "[2019-08-08 22:22:48,462 - INFO - pybda.fit.gmm_fit_profile]: Plotting profile to: results/2019_08_08/gmm_from_iris-profile.png\n",
      "[2019-08-08 22:22:51,947 - INFO - pybda.fit.clustering_fit_profile]: Plotting cluster sizes to: results/2019_08_08/gmm_from_iris-cluster_sizes-histogram.png\n",
      "[2019-08-08 22:22:53,737 - INFO - pybda.fit.gmm_fit_profile]: Plotting profile to: results/2019_08_08/gmm_from_iris-profile.pdf\n",
      "[2019-08-08 22:22:54,015 - INFO - pybda.fit.clustering_fit_profile]: Plotting cluster sizes to: results/2019_08_08/gmm_from_iris-cluster_sizes-histogram.pdf\n",
      "[2019-08-08 22:22:54,398 - INFO - pybda.fit.gmm_fit_profile]: Plotting profile to: results/2019_08_08/gmm_from_iris-profile.svg\n",
      "[2019-08-08 22:22:54,654 - INFO - pybda.fit.clustering_fit_profile]: Plotting cluster sizes to: results/2019_08_08/gmm_from_iris-cluster_sizes-histogram.svg\n",
      "[2019-08-08 22:22:55,080 - INFO - pybda.fit.gmm_fit_profile]: Plotting profile to: results/2019_08_08/gmm_from_iris-profile.eps\n",
      "[2019-08-08 22:22:55,348 - INFO - pybda.fit.clustering_fit_profile]: Plotting cluster sizes to: results/2019_08_08/gmm_from_iris-cluster_sizes-histogram.eps\n",
      "[2019-08-08 22:22:55,702 - INFO - pybda.decorators]: function: 'fit' took: 17.6145 sec\n",
      "[2019-08-08 22:22:55,714 - INFO - pybda.fit.gmm_transformed]: Writing components to: results/2019_08_08/gmm_from_iris-transformed-K3-components\n",
      "[2019-08-08 22:22:55,715 - INFO - pybda.spark.features]: Splitting vector columns: features\n",
      "[2019-08-08 22:22:55,863 - INFO - pybda.spark.features]: Splitting vector columns: responsibilities\n",
      "[2019-08-08 22:22:57,157 - INFO - pybda.fit.gmm_transformed]: Writing components to: results/2019_08_08/gmm_from_iris-transformed-K5-components\n",
      "[2019-08-08 22:22:57,161 - INFO - pybda.spark.features]: Splitting vector columns: features\n",
      "[2019-08-08 22:22:57,305 - INFO - pybda.spark.features]: Splitting vector columns: responsibilities\n",
      "[2019-08-08 22:22:57,833 - INFO - pybda.fit.gmm_transformed]: Writing components to: results/2019_08_08/gmm_from_iris-transformed-K10-components\n",
      "[2019-08-08 22:22:57,834 - INFO - pybda.spark.features]: Splitting vector columns: features\n",
      "[2019-08-08 22:22:57,951 - INFO - pybda.spark.features]: Splitting vector columns: responsibilities\n",
      "[2019-08-08 22:22:58,572 - INFO - pybda.spark_session]: Stopping Spark context\n",
      "[2019-08-08 22:22:58,572 - INFO - pybda.spark_session]: Closed spark context at: Thu Aug  8 22:22:58 2019\n",
      "[2019-08-08 22:22:58,572 - INFO - pybda.spark_session]: Computation took: 24\n",
      "(pybda) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cat */gmm_from_iris.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, the Spark `log` file is sometimes important to look at when the methods failed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-08 22:22:31 WARN  Utils:66 - Your hostname, hoto resolves to a loopback address: 127.0.1.1; using 192.168.1.33 instead (on interface wlp2s0)\n",
      "2019-08-08 22:22:31 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "2019-08-08 22:22:31 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2019-08-08 22:22:33 INFO  SparkContext:54 - Running Spark version 2.4.0\n",
      "2019-08-08 22:22:33 INFO  SparkContext:54 - Submitted application: gmm.py\n",
      "2019-08-08 22:22:33 INFO  SecurityManager:54 - Changing view acls to: simon\n",
      "2019-08-08 22:22:33 INFO  SecurityManager:54 - Changing modify acls to: simon\n",
      "2019-08-08 22:22:33 INFO  SecurityManager:54 - Changing view acls groups to: \n",
      "2019-08-08 22:22:33 INFO  SecurityManager:54 - Changing modify acls groups to: \n",
      "2019-08-08 22:22:33 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(simon); groups with view permissions: Set(); users  with modify permissions: Set(simon); groups with modify permissions: Set()\n",
      "(pybda) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "head */gmm_from_iris-spark.log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
