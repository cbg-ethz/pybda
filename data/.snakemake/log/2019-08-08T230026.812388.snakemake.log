Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	factor_analysis
	1	lda
	1	pca
	3

[Thu Aug  8 23:00:26 2019]
rule factor_analysis:
    input: iris.tsv
    output: results/2019_08_08/factor_analysis_from_iris.tsv, results/2019_08_08/factor_analysis_from_iris-loadings.tsv, results/2019_08_08/factor_analysis_from_iris-loglik.tsv, results/2019_08_08/factor_analysis_from_iris-plot
    jobid: 0

[Thu Aug  8 23:01:21 2019]
Finished job 0.
1 of 3 steps (33%) done

[Thu Aug  8 23:01:21 2019]
rule pca:
    input: iris.tsv
    output: results/2019_08_08/pca_from_iris.tsv, results/2019_08_08/pca_from_iris-loadings.tsv, results/2019_08_08/pca_from_iris-plot
    jobid: 1

[Thu Aug  8 23:02:03 2019]
Finished job 1.
2 of 3 steps (67%) done

[Thu Aug  8 23:02:03 2019]
rule lda:
    input: iris.tsv
    output: results/2019_08_08/lda.tsv, results/2019_08_08/lda-projection.tsv, results/2019_08_08/lda-plot
    jobid: 2

Removing output files of failed job lda since they might be corrupted:
results/2019_08_08/lda.tsv, results/2019_08_08/lda-projection.tsv, results/2019_08_08/lda-plot
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/simon/PROJECTS/pybda/data/.snakemake/log/2019-08-08T230026.812388.snakemake.log
